{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "P1",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Tm6uoROHz2sdn_DACXgPpx48t7hS7pN5",
      "authorship_tag": "ABX9TyN6Drsu70VQ+M4j7CiR7uxQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bogdanjianu150/Mask_RCNN/blob/main/P1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMwZ1n5-sZH_"
      },
      "source": [
        "from google.colab import drive \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErNORsGBzyWp"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Olyj75E-JeB"
      },
      "source": [
        "!pip uninstall keras -y\n",
        "!pip uninstall keras-nightly -y\n",
        "!pip uninstall keras-Preprocessing -y\n",
        "!pip uninstall keras-vis -y\n",
        "!pip uninstall tensorflow -y\n",
        "!pip uninstall h5py -y\n",
        "\n",
        "!pip install tensorflow==1.15.0\n",
        "!pip install keras==2.2.5\n",
        "!pip install h5py==2.10.0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65I0_RvczNIz"
      },
      "source": [
        "pip install 'h5py==2.10.0' --force-reinstall"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FyTcU_K042h"
      },
      "source": [
        "from imgaug import augmenters as iaa\n",
        "from drive.MyDrive.Mask_RCNN.mrcnn.config import Config\n",
        "from drive.MyDrive.Mask_RCNN.mrcnn import model as modellib\n",
        "from drive.MyDrive.Mask_RCNN.mrcnn import visualize\n",
        "from drive.MyDrive.Mask_RCNN.mrcnn import utils\n",
        "from imutils import paths\n",
        "import numpy as np\n",
        "import argparse\n",
        "import imutils\n",
        "import random\n",
        "import cv2\n",
        "import os\n",
        "import json\n",
        "from google.colab.patches import cv2_imshow\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXkTZ1N06OV2"
      },
      "source": [
        "!nvidia-smi\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvyUG7wP0Yax"
      },
      "source": [
        "dataset_path = os.path.abspath(\"/content/drive/MyDrive/trashnet\")\n",
        "images_path = os.path.abspath(\"/content/drive/MyDrive/trashnet/dataset\")\n",
        "masks_path = os.path.sep.join([dataset_path, \"masks.json\"])\n",
        "\n",
        "\n",
        "\n",
        "training_split = 0.75\n",
        "\n",
        "image_paths = sorted(list(paths.list_images(images_path)))\n",
        "idxs = list(range(0, len(image_paths) ))\n",
        "random.seed(42)\n",
        "random.shuffle(idxs)\n",
        "i = int(len(idxs) * training_split)\n",
        "train_idxs = idxs[:i]\n",
        "val_idxs = idxs[i:]\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffwsufpb4RO-"
      },
      "source": [
        "class_names = {1 : \"cardboard\", 2 : \"glass\", 3: \"paper\", 4: \"plastic\", 5: \"metal\", 6: \"trash\"}\n",
        "#class_names ={1: \"trash\"}\n",
        "\n",
        "coco_path = \"/content/drive/MyDrive/mask_rcnn_coco.h5\"\n",
        "\n",
        "LOGS_AND_MODEL_DIR = \"logs\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnJn8fyG5B7W"
      },
      "source": [
        "class TrashConfig(Config):\n",
        "  NAME = 'trash'\n",
        "  GPU_COUNT = 1\n",
        "  IMAGES_PER_GPU = 1\n",
        "  STEPS_PER_EPOCH = len(train_idxs) // (IMAGES_PER_GPU * GPU_COUNT)\n",
        "  NUM_CLASSES = len(class_names) + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Psewri265nCe"
      },
      "source": [
        "class TrashInferenceConfig(TrashConfig):\n",
        "  GPU_COUNT = 1\n",
        "  IMAGES_PER_GPU = 1\n",
        "  DETECTION_MIN_CONFIDENCE = 0.9\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-2iDAY-54iE"
      },
      "source": [
        "class TrashDataset(utils.Dataset):\n",
        "  def __init__(self, imagePaths, masksPath, classNames, width = 1024):\n",
        "    super().__init__(self)\n",
        "    self.imagePaths = imagePaths\n",
        "    self.classNames = classNames\n",
        "    self.width = width\n",
        "    self.masks = self.load_mask_data(masksPath)\n",
        "\n",
        "  def load_mask_data(self, masksPath):\n",
        "   masks = json.loads(open(masksPath).read())\n",
        "  \n",
        "   return masks\n",
        "\n",
        "  def load_trash(self, idxs):\n",
        "    for (class_id, label) in  self.classNames.items():\n",
        "      self.add_class(\"trash\", class_id, label)\n",
        "\n",
        "\n",
        "    image_path = os.listdir(self.imagePaths)\n",
        "\n",
        "    for i in image_path :\n",
        "      #image_path = os.listdir(self.imagePaths)\n",
        "      #filename = image_path.split(os.path.sep)[-1]\n",
        "      \n",
        "      k = self.imagePaths + '/' + i\n",
        "      filename = k.split(os.path.sep)[-1]\n",
        "      image = cv2.imread(k)\n",
        "      self.add_image(\"trash\", image_id = filename, path = k)\n",
        "  \n",
        "  def load_image(self, image_id):\n",
        "   p = self.image_info[image_id][\"path\"]\n",
        "   image = cv2.imread(p)\n",
        "   image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "   image = imutils.resize(image, width = self.width)\n",
        "   return image\n",
        "\n",
        "  def load_mask(self, image_id):\n",
        "   image_info = self.image_info[image_id]\n",
        "   if image_info[\"source\"] != \"/content/drive/MyDrive/trashnet/dataset\":\n",
        "    return super(self.__class__, self).load_mask(image_id)\n",
        "   info = self.image_info[imageID]\n",
        "   m2 = self.m[info[\"id\"]]\n",
        "\n",
        "   masks = np.zeros((info[\"height\"], info[\"width\"], len(m2[\"regions\"])), dtype = \"uint8\")\n",
        "\n",
        "   for (i, region) in enumerate(m2[\"regions\"]) :\n",
        "    region_mask = np.zeros(masks2.shape[:2], dtype = \"uint8\")\n",
        "    sa = region[\"shape_attributes\"]\n",
        "    ra = region[\"region_attributes\"]\n",
        "    ratio = info[\"width\"] / float(info[\"orig_width\"])\n",
        "    cX = int(sa[\"cx\"] * ratio)\n",
        "    cY = int(sa[\"cy\"] * ratio)\n",
        "    r = int(sa[\"r\"] * ratio)\n",
        "\n",
        "    \n",
        "\n",
        "    cv2.circle(region_mask, (cX, cY), r, 1, -1)\n",
        "    \n",
        "    masks[:, :, i] = region_mask\n",
        "\n",
        "   return (masks2.astype(\"bool\"), np.ones((masks.shape[-1], ), dtype =\"int32\"))\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tP2MvoqceLEP"
      },
      "source": [
        "train_dataset = TrashDataset(images_path, masks_path, class_names)\n",
        "train_dataset.load_trash(train_idxs)\n",
        "train_dataset.prepare()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlVSx34KeQfO"
      },
      "source": [
        "val_dataset = TrashDataset(images_path, masks_path, class_names)\n",
        "val_dataset.load_trash(val_idxs)\n",
        "val_dataset.prepare()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AX5Grp0ReUtn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bc1f7f9-31f8-40b0-f537-0adced6a0dce"
      },
      "source": [
        "config = TrashConfig()\n",
        "config.display()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Configurations:\n",
            "BACKBONE                       resnet101\n",
            "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
            "BATCH_SIZE                     1\n",
            "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
            "COMPUTE_BACKBONE_SHAPE         None\n",
            "DETECTION_MAX_INSTANCES        100\n",
            "DETECTION_MIN_CONFIDENCE       0.7\n",
            "DETECTION_NMS_THRESHOLD        0.3\n",
            "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
            "GPU_COUNT                      1\n",
            "GRADIENT_CLIP_NORM             5.0\n",
            "IMAGES_PER_GPU                 1\n",
            "IMAGE_CHANNEL_COUNT            3\n",
            "IMAGE_MAX_DIM                  1024\n",
            "IMAGE_META_SIZE                14\n",
            "IMAGE_MIN_DIM                  800\n",
            "IMAGE_MIN_SCALE                0\n",
            "IMAGE_RESIZE_MODE              square\n",
            "IMAGE_SHAPE                    [1024 1024    3]\n",
            "LEARNING_MOMENTUM              0.9\n",
            "LEARNING_RATE                  0.001\n",
            "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
            "MASK_POOL_SIZE                 14\n",
            "MASK_SHAPE                     [28, 28]\n",
            "MAX_GT_INSTANCES               100\n",
            "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
            "MINI_MASK_SHAPE                (56, 56)\n",
            "NAME                           trash\n",
            "NUM_CLASSES                    2\n",
            "POOL_SIZE                      7\n",
            "POST_NMS_ROIS_INFERENCE        1000\n",
            "POST_NMS_ROIS_TRAINING         2000\n",
            "PRE_NMS_LIMIT                  6000\n",
            "ROI_POSITIVE_RATIO             0.33\n",
            "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
            "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
            "RPN_ANCHOR_STRIDE              1\n",
            "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
            "RPN_NMS_THRESHOLD              0.7\n",
            "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
            "STEPS_PER_EPOCH                1890\n",
            "TOP_DOWN_PYRAMID_SIZE          256\n",
            "TRAIN_BN                       False\n",
            "TRAIN_ROIS_PER_IMAGE           200\n",
            "USE_MINI_MASK                  True\n",
            "USE_RPN_ROIS                   True\n",
            "VALIDATION_STEPS               50\n",
            "WEIGHT_DECAY                   0.0001\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:You are using the default load_mask(), maybe you need to define your own one.\n",
            "WARNING:root:You are using the default load_mask(), maybe you need to define your own one.\n",
            "WARNING:root:You are using the default load_mask(), maybe you need to define your own one.\n",
            "WARNING:root:You are using the default load_mask(), maybe you need to define your own one.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K61KQloleeGO"
      },
      "source": [
        "model = modellib.MaskRCNN(mode = \"training\", config = config, model_dir = LOGS_AND_MODEL_DIR)\n",
        "model.load_weights(coco_path, by_name = True, exclude = [\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "\n",
        "model.train(train_dataset, val_dataset, epochs = 20, layers = \"heads\", learning_rate = config.LEARNING_RATE)\n",
        "model.train(train_dataset, val_dataset, epochs = 40, layers = \"all\", learning_rate = config.LEARNING_RATE / 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIyYdKDsDCym"
      },
      "source": [
        "config = TrashInferenceConfig()\n",
        "model = modellib.MaskRCNN(mode = \"inference\", config = config, model_dir = logs_and_model_dir)\n",
        "\n",
        "weights = args[\"weights\"] if args[weights] else model.find_last()\n",
        "model.load_weigths(weights, by_name = True )\n",
        "\n",
        "\n",
        "image = cv2.imread(args[\"image\"])\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "image = imutils.resize(image, width = 1024)\n",
        "\n",
        "r = model.detect([image], verbose = 1)[0]\n",
        "\n",
        "for i in range(0, r[\"rois\"].shape[0]):\n",
        "  mask = r[\"masks\"][:, :, i]\n",
        "  image = visualize.apply_mask(image, mask, (1.0, 0.0, 0.0), alpha = 0.5)\n",
        "  image = visualize.draw_box(image, r[\"rois\"][i], [1.0, 0.0, 0.0])\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "  for i in range(0, len(r[\"scores\"])):\n",
        "   (startY, startX, endY, endX) = r[\"rois\"][i]\n",
        "   class_id = r[\"class_ids\"][i]\n",
        "   label = class_names[class_id]\n",
        "   score = r[\"scores\"][i]\n",
        "\n",
        "   text = \"{}: {:.4f}\".format(label, score)\n",
        "   y = startY - 10 if startY - 10 > 10 else startY + 10\n",
        "   cv2.putText(image, text, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
        "      \n",
        "image = imutils.resize(image, width = 512)\n",
        "cv2.imshow(\"Output\", image)\n",
        "cv2.waitKey(0)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}